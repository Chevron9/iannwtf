{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = tfds.load(\"malaria\", as_supervised=True, data_dir=\"data\\\\\",split=\"train[:80%]\")\n",
    "test = tfds.load(\"malaria\", as_supervised=True, data_dir=\"data\\\\\",split=\"train[80%:]\")\n",
    "max_x = max_y = max_z = 0\n",
    "min_x = min_y = min_z = 400\n",
    "\n",
    "train2 = tfds.load(\"malaria\", as_supervised=True, data_dir=\"data\\\\\",split=\"train[:80%]\")\n",
    "for i in train2:\n",
    "    # print(i)\n",
    "    for j in i:\n",
    "        if j.dtype==tf.uint8:\n",
    "            (x, y, z) = j.shape\n",
    "            max_x = max(x,max_x)\n",
    "            max_y = max(y,max_y)\n",
    "            max_z = max(z,max_z)\n",
    "\n",
    "            min_x = min(x,min_x)\n",
    "            min_y = min(y,min_y)\n",
    "            min_z = min(z,min_z)\n",
    "print(max_x, max_y, max_z, min_x, min_y, min_z)"
   ]
  },
  {
   "source": [
    "Alright, we need first a feature extractor then a classifier\n",
    "\n",
    "What are the classes that we are looking for? It's infected and non-infected. \n",
    "\n",
    "Our first attempt will be to go minimalistic: After all, it's most resource-efificent to go with the least complexity necessary.\n",
    "\n",
    "This means:\n",
    "* Input\n",
    "* One convolution layer\n",
    "* Pool\n",
    "* Classifier (output)\n",
    "\n",
    "One issue we are facing is that the dataset images are of very different sizes. This will require padding!\n",
    "Which type of padding do we want to use? The differences in dimensions are staggering!\n",
    "It would be a good idea to print some of the images, especially large and small ones, to see how padding would affect them.\n",
    "\n",
    "Options are:\n",
    "* Crop to quadratic shape\n",
    "* Resize and fill the empty space with zeroes\n",
    "* resize and stretch the image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_plot(train,imgs=55,greyscale=False,scale=False):\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    columns = 4\n",
    "    rows = 10\n",
    "    fig, ax = plt.subplots(1,imgs)\n",
    "    for i,j in enumerate(train):\n",
    "        img= j[0]\n",
    "        lbl = j[1].numpy()\n",
    "        subax = fig.add_subplot(rows+1,columns+1,i+1)   \n",
    "        subax.axis(\"off\")\n",
    "        subax.set_title(lbl)\n",
    "\n",
    "        if greyscale:\n",
    "            if scale:\n",
    "                plt.imshow(np.squeeze(img),vmin=-2, vmax= 2.5,cmap=\"gray\")\n",
    "            else:\n",
    "                plt.imshow(tf.cast(np.squeeze(img),tf.uint8),cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(tf.cast(img,tf.uint8))\n",
    "        # ax[i].set_title(lbl)\n",
    "        ax[i].axis(\"off\")\n",
    "        if i == (imgs-1): #this is really awkward, but sadly prefetch_datasets are quite particular about indexing\n",
    "            break\n",
    "    plt.subplots_adjust(top=3)\n",
    "    plt.show()\n",
    "\n",
    "tile_plot(train)\n",
    "# tile_plot(train,greyscale=True,scale=True)"
   ]
  },
  {
   "source": [
    "It appears as though the images are already zero-padded anyways, so my first instinct would be to apply zero padding. This also makes sense because it preserves the information of cell size, which might be interesting to have."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = tfds.load(\"malaria\", as_supervised=True, data_dir=\"data\\\\\",split=\"train[:80%]\")\n",
    "test = tfds.load(\"malaria\", as_supervised=True, data_dir=\"data\\\\\",split=\"train[80%:]\")\n",
    "\n",
    "target_height = 400\n",
    "target_width = 400\n",
    "\n",
    "train = train.map(lambda x,y : (tf.image.resize_with_pad(x, target_height, target_width, method=tf.image.ResizeMethod.LANCZOS3, antialias=False), tf.reshape(tf.one_hot(y, 2), (-1,) )))\n",
    "test = test.map(lambda x,y : (tf.image.resize_with_pad(x, target_height, target_width, method=tf.image.ResizeMethod.LANCZOS3, antialias=False), tf.reshape(tf.one_hot(y, 2), (-1,) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_plot(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)\n",
    "train = train.map(lambda x,y  : (tf.image.rgb_to_grayscale(x), y) )\n",
    "print(train)\n",
    "tile_plot(train,greyscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data\n",
    "train = train.map(lambda x,y: (tf.image.per_image_standardization(\n",
    "    x), y))\n",
    "test = test.map(lambda x,y: (tf.image.per_image_standardization(\n",
    "    x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tile_plot(train,greyscale=True,scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<PrefetchDataset shapes: ((None, 400, 400, 1), (None, 2)), types: (tf.float32, tf.float32)>\n",
      "(<tf.Tensor: shape=(32, 400, 400, 1), dtype=float32, numpy=\n",
      "array([[[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]]], dtype=float32)>, <tf.Tensor: shape=(32, 2), dtype=float32, numpy=\n",
      "array([[0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "train = train.batch(32).shuffle(buffer_size=32).prefetch(1)\n",
    "test = test.batch(32).shuffle(buffer_size=32).prefetch(1)\n",
    "\n",
    "print(train)\n",
    "for i in train:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class Model(Model): \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # Define the 9 layers, alternating between convolutional(relu) and pooling layers, ending with global\n",
    "        # average pooling and an softmax output layer\n",
    "        self.conv_layer_1= tf.keras.layers.Conv2D(filters= 25, kernel_size= 3, strides=(1, 1), padding='valid',  activation=tf.keras.activations.relu)\n",
    "\n",
    "        self.pool_layer_2= tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2,2), padding='valid')\n",
    "\n",
    "        self.conv_layer_3= tf.keras.layers.Conv2D(filters= 25, kernel_size= 3, strides=(1, 1), padding='valid',  activation=tf.keras.activations.relu)\n",
    "\n",
    "        self.pool_layer_4= tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2,2), padding='valid')\n",
    "\n",
    "        self.conv_layer_5= tf.keras.layers.Conv2D(filters= 25, kernel_size= 3, strides=(1, 1), padding='valid',  activation=tf.keras.activations.relu)\n",
    "\n",
    "        self.pool_layer_6= tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2,2), padding='valid')\n",
    "\n",
    "        self.conv_layer_7= tf.keras.layers.Conv2D(filters= 25, kernel_size= 3, strides=(1, 1), padding='valid',  activation=tf.keras.activations.relu)\n",
    "\n",
    "        self.global_pooling_layer_8 = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "        self.output_layer_10 = tf.keras.layers.Dense(units=2, activation=tf.keras.activations.softmax)\n",
    "\n",
    "    #propagates the input through the network\n",
    "    #tf.function decorator models function as a graph\n",
    "    @tf.function \n",
    "    def call(self, x):\n",
    "        # Define the forward step.\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.pool_layer_2(x)\n",
    "        x = self.conv_layer_3(x)\n",
    "        x = self.pool_layer_4(x)\n",
    "        x = self.conv_layer_5(x)\n",
    "        x = self.pool_layer_6(x)\n",
    "        x = self.conv_layer_7(x)\n",
    "        x = self.global_pooling_layer_8(x)\n",
    "        x = self.output_layer_10(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, data, target, loss_function, optimizer):\n",
    "  # loss_object and optimizer_object are instances of respective tensorflow classes\n",
    "  with tf.GradientTape() as tape:\n",
    "    prediction = model(data)\n",
    "    loss = loss_function(target, prediction)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  return loss \n",
    "\n",
    "def test_step(model, test, loss_function):\n",
    "  # test over complete test data\n",
    "\n",
    "  test_accuracy_aggregator = []\n",
    "  test_loss_aggregator = []\n",
    "\n",
    "  for (data, target) in test:\n",
    "    prediction = model(data)\n",
    "    sample_test_loss = loss_function(target, prediction)\n",
    "    sample_test_accuracy =  np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
    "    sample_test_accuracy = np.mean(sample_test_accuracy)\n",
    "\n",
    "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
    "    test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
    "\n",
    "  test_loss = np.mean(test_loss_aggregator)\n",
    "  test_accuracy = np.mean(test_accuracy_aggregator)\n",
    "\n",
    "  return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-10-fd4a91bf9b17>:33 call  *\n        x = self.conv_layer_1(x)\n    F:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__  **\n        self.name)\n    F:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer conv2d is incompatible with the layer: expected axis -1 of input shape to have value 3 but received input with shape [32, 400, 400, 1]\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-8c1980c491cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#check how model performs on train data once before we begin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-65cb8da653c2>\u001b[0m in \u001b[0;36mtest_step\u001b[1;34m(model, test, loss_function)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0msample_test_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0msample_test_accuracy\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3733\u001b[0m     \u001b[1;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3734\u001b[0m     \u001b[1;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3735\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3736\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-10-fd4a91bf9b17>:33 call  *\n        x = self.conv_layer_1(x)\n    F:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__  **\n        self.name)\n    F:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer conv2d is incompatible with the layer: expected axis -1 of input shape to have value 3 but received input with shape [32, 400, 400, 1]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "### Hyperparameters\n",
    "num_epochs = 2\n",
    "learning_rate = 0.0001\n",
    "running_average_factor = 0.95\n",
    "\n",
    "# Initialize the model.\n",
    "model = Model()\n",
    "# Initialize the loss: categorical cross entropy. Check out 'tf.keras.losses'.\n",
    "cross_entropy_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "# Initialize the optimizer: Adam with default parameters. Check out 'tf.keras.optimizers'\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "# Initialize lists for later visualization.\n",
    "train_losses = []\n",
    "\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "#testing once before we begin\n",
    "test_loss, test_accuracy = test_step(model, test, cross_entropy_loss)\n",
    "test_losses.append(test_loss)\n",
    "test_accuracies.append(test_accuracy)\n",
    "\n",
    "#check how model performs on train data once before we begin\n",
    "train_loss, _ = test_step(model, train, cross_entropy_loss)\n",
    "train_losses.append(train_loss)\n",
    "\n",
    "# We train for num_epochs epochs.\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch: __ ' + str(epoch))\n",
    "\n",
    "    train = train.shuffle(buffer_size=128)\n",
    "    test = test.shuffle(buffer_size=128)\n",
    "\n",
    "    #training (and checking in with training)\n",
    "    running_average = 0\n",
    "    for (data,target) in train:\n",
    "        train_loss = train_step(model, data, target, cross_entropy_loss, optimizer)\n",
    "        running_average = running_average_factor * running_average  + (1 - running_average_factor) * train_loss\n",
    "    train_losses.append(running_average)\n",
    "\n",
    "    #testing\n",
    "    test_loss, test_accuracy = test_step(model, test, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize accuracy and loss for training and test data. \n",
    "# One plot training and test loss.\n",
    "# One plot training and test accuracy.\n",
    "plt.figure()\n",
    "line1, = plt.plot(train_losses)\n",
    "line2, = plt.plot(test_losses)\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend((line1,line2),(\"training\",\"test\"))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "line1, = plt.plot(test_accuracies)\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ]
}