{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = tfds.load(\"malaria\", as_supervised=True, data_dir=\"data\\\\\",split=\"train\")\n",
    "\n",
    "for i in train:\n",
    "    # print(i)\n",
    "    for j in i:\n",
    "        # print(j)\n",
    "        (x, y, z) = j.shape\n",
    "        print(x)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "source": [
    "Alright, we need first a feature extractor then a classifier\n",
    "\n",
    "What are the classes that we are looking for? It's infected and non-infected. \n",
    "\n",
    "Our first attempt will be to go minimalistic: After all, it's most resource-efificent to go with the least complexity necessary.\n",
    "\n",
    "This means:\n",
    "* Input\n",
    "* One convolution layer\n",
    "* Pool\n",
    "* Classifier (output)\n",
    "\n",
    "One issue we are facing is that the dataset images are of very different sizes. This wil"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.Conv2D(\n",
    "    filters, kernel_size, strides=(1, 1), padding='valid', data_format=None,\n",
    "    dilation_rate=(1, 1), groups=1, activation=None, use_bias=True,\n",
    "    kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "    kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "    kernel_constraint=None, bias_constraint=None, **kwargs\n",
    ")\n",
    "\n",
    "tf.keras.layers.MaxPool2D(\n",
    "    pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs\n",
    ")\n",
    "\n",
    "tf.keras.layers.GlobalAveragePooling2D(\n",
    "    data_format=None, **kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class Model(Model): \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # Define the three layers.\n",
    "        self.hidden_layer_1 = tf.keras.layers.Dense(units=256,\n",
    "                                               activation=tf.keras.activations.sigmoid\n",
    "                                               )\n",
    "        self.hidden_layer_2 = tf.keras.layers.Dense(units=256,\n",
    "                                               activation=tf.keras.activations.sigmoid\n",
    "                                               )\n",
    "        self.output_layer = tf.keras.layers.Dense(units=10,\n",
    "                                               activation=tf.keras.activations.softmax\n",
    "                                               )\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        # Define the forward step.\n",
    "        x = self.hidden_layer_1(x)\n",
    "        x = self.hidden_layer_2(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  }
 ]
}