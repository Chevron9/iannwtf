{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37264bit7266801a3daa40d0bd4353bac9859f3d",
   "display_name": "Python 3.7.2 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#%tensorflow_version 2.x\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, datasets_info = tfds.load(name='fashion_mnist',\n",
    "                                    with_info=True,\n",
    "                                    as_supervised=False,\n",
    "                                    data_dir=\"data\\\\VAE\\\\\")\n",
    "\n",
    "def _preprocess(sample):\n",
    "  image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\n",
    "  image = image < tf.random.uniform(tf.shape(image))   # Randomly binarize.\n",
    "  return image, image\n",
    "\n",
    "train_ds = (datasets['train']\n",
    "                 .map(_preprocess)\n",
    "                 .batch(64, drop_remainder=True)\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                 .shuffle(int(10e3)))\n",
    "test_ds = (datasets['test']\n",
    "                .map(_preprocess)\n",
    "                .batch(64, drop_remainder=True)\n",
    "                .prefetch(tf.data.experimental.AUTOTUNE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_plot(train,imgs=55,greyscale=True,scale=False,labelling=True):\n",
    "    # This function plots the images in a tiled fashion, for better visualization.\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    columns = 4\n",
    "    rows = 10\n",
    "    fig, ax = plt.subplots(1,imgs)\n",
    "    for i,j in enumerate(tfds.as_numpy(train)):\n",
    "        print(j)\n",
    "        img= j[0]\n",
    "        \n",
    "        label = {\n",
    "        0 : 'T-shirt/top',\n",
    "        1 : 'Trouser',\n",
    "        2 : 'Pullover',\n",
    "        3 : 'Dress',\n",
    "        4 : 'Coat',\n",
    "        5 : 'Sandal',\n",
    "        6 : 'Shirt',\n",
    "        7 : 'Sneaker',\n",
    "        8 : 'Bag',\n",
    "        9 : 'Ankle boot'\n",
    "        }\n",
    "        # if label is still just an integer\n",
    "        if isinstance(j[1], np.int64):\n",
    "            if labelling:\n",
    "                lbl = label[j[1]]\n",
    "        else:\n",
    "            indice = np.where(j[1] == 1)\n",
    "            indice = indice[0]\n",
    "            if labelling:\n",
    "                lbl = label[int(indice)]\n",
    "        subax = fig.add_subplot(rows+1,columns+1,i+1)   \n",
    "        subax.axis(\"off\")\n",
    "        if labelling:\n",
    "            subax.set_title(lbl)\n",
    "\n",
    "        if greyscale: #Dealing with grayscale images requires a different approach, since imshow doesn't handle them as adroitly as RGB\n",
    "            if scale: # This is to visualize our normalized images. Since this doesn't conform to the standard scale, we have to define our own\n",
    "                plt.imshow(np.squeeze(img),vmin=-2, vmax= 2.5,cmap=\"gray\")\n",
    "            else:\n",
    "                plt.imshow(tf.cast(np.squeeze(img),tf.uint8),cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(tf.cast(img,tf.uint8)) #cast to uint because otherwise there's an error from matplotlib\n",
    "        ax[i].axis(\"off\")\n",
    "        if i == (imgs-1): \n",
    "            # this is really awkward, but sadly prefetch_datasets are quite particular about indexing.\n",
    "            # converting them to numpy first might be smarter in the future\n",
    "            break\n",
    "    plt.subplots_adjust(top=3)\n",
    "    plt.show()\n",
    "\n",
    "#tile_plot(train_dataset,labelling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_plot(data):\n",
    "    for i in data:\n",
    "        i = i[0][0]\n",
    "        #print(tf.cast(i[0],tf.uint8))\n",
    "        print(np.squeeze(tfds.as_numpy(tf.cast(i,tf.uint8))).shape)\n",
    "        plt.imshow(np.squeeze((tfds.as_numpy(tf.cast(i,tf.uint8)))))\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "# binary_plot(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(total_epochs, train_loss, test_loss, timing):\n",
    "    \"\"\"Helper function to plot the models performance inline during and after training\"\"\"\n",
    "    #clear_output(wait=True) # Clear the previous graph\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12,6))\n",
    "    # Estimation for remaining time\n",
    "    epoch = len(train_loss) - 1\n",
    "    remaining_time = (timing[1] - timing[0]) * (total_epochs - epoch)\n",
    "    fig.suptitle(f\"Epoch {epoch} / {total_epochs} - Remaining Training Time: {time.strftime('%M:%S', time.gmtime(remaining_time))} min\", fontsize=16)\n",
    "\n",
    "    ax[0].plot(train_loss)\n",
    "    ax[0].plot(test_loss)\n",
    "    ax[0].legend([\"training\", \"test\"])\n",
    "    ax[0].set(xlabel=\"Training Steps\", ylabel=\"Loss\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = datasets_info.features['image'].shape\n",
    "encoded_size = 16\n",
    "base_depth = 32\n",
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
    "                        reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class V_Encoder(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(V_Encoder, self).__init__()\n",
    "\n",
    "        self.hidden = [\n",
    "            tfkl.InputLayer(input_shape=input_shape),\n",
    "            tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),\n",
    "            tfkl.Conv2D(base_depth, 5, strides=1,\n",
    "                        padding='same', activation=tf.nn.leaky_relu),\n",
    "            tfkl.Conv2D(base_depth, 5, strides=2,\n",
    "                        padding='same', activation=tf.nn.leaky_relu),\n",
    "            tfkl.Conv2D(2 * base_depth, 5, strides=2,\n",
    "                        padding='same', activation=tf.nn.leaky_relu),\n",
    "            tfkl.Conv2D(4 * encoded_size, 7, strides=1,\n",
    "                        padding='valid', activation=tf.nn.leaky_relu),\n",
    "            tfkl.Flatten(),\n",
    "            tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),\n",
    "                        activation=None),\n",
    "            tfpl.MultivariateNormalTriL(encoded_size,\n",
    "                                        activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\n",
    "\n",
    "        ]\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self,x,training):\n",
    "        for i in self.hidden:\n",
    "            x = i(x,training=training)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class V_Decoder(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(V_Decoder, self).__init__()\n",
    "\n",
    "        self.hidden = [\n",
    "            tfkl.InputLayer(input_shape=[encoded_size]),\n",
    "            tfkl.Reshape([1, 1, encoded_size]),\n",
    "            tfkl.Conv2DTranspose(2 * base_depth, 7, strides=1,\n",
    "                                padding='valid', activation=tf.nn.leaky_relu),\n",
    "            tfkl.Conv2DTranspose(2 * base_depth, 5, strides=1,\n",
    "                                padding='same', activation=tf.nn.leaky_relu),\n",
    "            tfkl.Conv2DTranspose(2 * base_depth, 5, strides=2,\n",
    "                                padding='same', activation=tf.nn.leaky_relu),\n",
    "            tfkl.Conv2DTranspose(base_depth, 5, strides=2,\n",
    "                                padding='same', activation=tf.nn.leaky_relu),\n",
    "            tfkl.Conv2DTranspose(base_depth, 5, strides=1,\n",
    "                                padding='same', activation=tf.nn.leaky_relu),\n",
    "            tfkl.Conv2D(filters=1, kernel_size=5, strides=1,\n",
    "                        padding='same', activation=None),\n",
    "            tfkl.Flatten(),\n",
    "            tfpl.IndependentBernoulli(input_shape, tfd.Bernoulli.logits),\n",
    "        ]\n",
    "\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self,x,training):\n",
    "        for i in self.hidden:\n",
    "            x = i(x,training=training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Note, it's common practice to avoid using batch normalization when training VAEs, since the additional stochasticity due to using mini-batches may aggravate instability on top of the stochasticity from sampling."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.hidden = [\n",
    "            V_Encoder(),\n",
    "            V_Decoder()\n",
    "        ]\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self,x,training):\n",
    "        for i in self.hidden:\n",
    "            x = i(x,training=training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, data, target, loss_function, optimizer):\n",
    "  # loss_object and optimizer_object are instances of respective tensorflow classes\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    prediction = model(data, training = True)\n",
    "    loss = loss_function(target, prediction)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  \n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  \n",
    "  return loss \n",
    "\n",
    "\n",
    "def test_step(model, test_data, loss_function):\n",
    "  # test over complete test data\n",
    "\n",
    "  test_loss_aggregator = []\n",
    "\n",
    "  for (data, target) in test_data:\n",
    "    prediction = model(data, training = False)\n",
    "    \n",
    "    #print(target.shape)\n",
    "    #print(prediction.shape)\n",
    "    sample_test_loss = loss_function(target, prediction)\n",
    "    #print(sample_test_loss)\n",
    "\n",
    "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
    "\n",
    "  test_loss = np.mean(test_loss_aggregator)\n",
    "\n",
    "  return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training started at 16:49:14.\n",
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "v__encoder (V_Encoder)       multiple                  390840    \n",
      "_________________________________________________________________\n",
      "v__decoder (V_Decoder)       multiple                  358465    \n",
      "=================================================================\n",
      "Total params: 749,305\n",
      "Trainable params: 749,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch: __ 0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__float__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    985\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__float__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-e6d5741161cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mplot_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-74e5d2838f47>\u001b[0m in \u001b[0;36mplot_performance\u001b[1;34m(total_epochs, train_loss, test_loss, timing)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {epoch} / {total_epochs} - Remaining Training Time: {time.strftime('%M:%S', time.gmtime(remaining_time))} min\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"training\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1611\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36madd_line\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   1893\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1897\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_line%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m         \"\"\"\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36mget_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    943\u001b[0m         \"\"\"\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36mrecache\u001b[1;34m(self, always)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m             \u001b[0myconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_yorig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "### Hyperparameters\n",
    "num_epochs = 1\n",
    "learning_rate = tf.optimizers.schedules.ExponentialDecay(0.001, 5000, 0.97, staircase=True) #polynomial?\n",
    "running_average_factor = 0.95\n",
    "\n",
    "# Initialize the model.\n",
    "model = VAE()\n",
    "\n",
    "\n",
    "# Initialize the loss: categorical cross entropy. Check out 'tf.keras.losses'.\n",
    "# loss_func = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_func = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "\n",
    "# Initialize the optimizer: Adam with default parameters. Check out 'tf.keras.optimizers'\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "# Initialize lists for later visualization.\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "#\n",
    "t = time.localtime()\n",
    "current_time = time.strftime(\"%H:%M:%S\", t)\n",
    "print(f\"Training started at {current_time}.\")\n",
    "\n",
    "#testing once before we begin\n",
    "test_loss = test_step(model, test_ds, loss_func)\n",
    "test_losses.append(test_loss)\n",
    "\n",
    "#check how model performs on train data once before we begin\n",
    "train_loss = test_step(model, train_ds, loss_func)\n",
    "train_losses.append(train_loss)\n",
    "print(model.summary())\n",
    "\n",
    "# We train for num_epochs epochs.\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.perf_counter()\n",
    "    print('Epoch: __ ' + str(epoch))\n",
    "\n",
    "    #training (and checking in with training)\n",
    "    running_average = 0\n",
    "    for (data,target) in train_ds:\n",
    "        #train_loss = train_step(model, data, target, loss_func, optimizer)\n",
    "        train_loss = train_step(model, data, target, loss_func, optimizer)\n",
    "        running_average = running_average_factor * running_average  + (1 - running_average_factor) * train_loss\n",
    "    train_losses.append(running_average)\n",
    "\n",
    "    #testing\n",
    "    test_loss= test_step(model, test_ds, loss_func)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    print(train_lossses)\n",
    "    plot_performance(num_epochs, train_losses, test_losses, (start, end))\n",
    "\n",
    "t2 = time.localtime()\n",
    "current_time2 = time.strftime(\"%H:%M:%S\", t)\n",
    "t_delta = time.mktime(t2)-time.mktime(t)\n",
    "print(f\"Training ended at {current_time}. Duration was {t_delta/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll just examine ten random digits.\n",
    "x = next(iter(eval_dataset))[0][:10]\n",
    "xhat = vae(x)\n",
    "assert isinstance(xhat, tfd.Distribution)\n",
    "\n",
    "def display_imgs(x, y=None):\n",
    "  if not isinstance(x, (np.ndarray, np.generic)):\n",
    "    x = np.array(x)\n",
    "  plt.ioff()\n",
    "  n = x.shape[0]\n",
    "  fig, axs = plt.subplots(1, n, figsize=(n, 1))\n",
    "  if y is not None:\n",
    "    fig.suptitle(np.argmax(y, axis=1))\n",
    "  for i in range(n):\n",
    "    axs.flat[i].imshow(x[i].squeeze(), interpolation='none', cmap='gray')\n",
    "    axs.flat[i].axis('off')\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "  plt.ion()\n",
    "\n",
    "print('Originals:')\n",
    "display_imgs(x)\n",
    "\n",
    "print('Decoded Random Samples:')\n",
    "display_imgs(xhat.sample())\n",
    "\n",
    "print('Decoded Modes:')\n",
    "display_imgs(xhat.mode())\n",
    "\n",
    "print('Decoded Means:')\n",
    "display_imgs(xhat.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's generate ten never-before-seen digits.\n",
    "z = prior.sample(10)\n",
    "xtilde = decoder(z)\n",
    "assert isinstance(xtilde, tfd.Distribution)\n",
    "\n",
    "print('Randomly Generated Samples:')\n",
    "display_imgs(xtilde.sample())\n",
    "\n",
    "print('Randomly Generated Modes:')\n",
    "display_imgs(xtilde.mode())\n",
    "\n",
    "print('Randomly Generated Means:')\n",
    "display_imgs(xtilde.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = model(data,training=False).numpy()\n",
    "\n",
    "x_test = list(map(lambda x: x[0], test_ds))\n",
    "x_test = tfds.as_numpy(test_ds)\n",
    "n = 15\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  #display original\n",
    "  ax = plt.subplot(2, n, i + 1)\n",
    "  plt.imshow(np.squeeze(data[i]))\n",
    "  plt.title(\"original\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reconstruction\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  #ax = plt.subplot(2, n, i + 1)\n",
    "  # print(images[i].shape)\n",
    "  plt.imshow(np.squeeze(images[i]))\n",
    "  plt.title(\"construct\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}